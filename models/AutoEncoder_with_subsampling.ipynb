{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AutoEncoder_with_subsampling.ipynb","provenance":[],"collapsed_sections":["NkCdxVsxC2E9"],"machine_shape":"hm","authorship_tag":"ABX9TyPY6lu7Kxbwwgs2cYQIupUI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Load Data"],"metadata":{"id":"NkCdxVsxC2E9"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"gH3xPyRZlL85","executionInfo":{"status":"ok","timestamp":1658831175211,"user_tz":-540,"elapsed":637,"user":{"displayName":"신현호","userId":"08804028255972704707"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import warnings\n","warnings.filterwarnings('ignore')\n","from IPython.display import display, Markdown\n","plt.style.use('ggplot')"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xB7vJUXVlqB0","executionInfo":{"status":"ok","timestamp":1658831203994,"user_tz":-540,"elapsed":28786,"user":{"displayName":"신현호","userId":"08804028255972704707"}},"outputId":"fd6462b1-be61-493a-cb11-743d4b3f9112"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/dacon_anomaly')"],"metadata":{"id":"pNLU9DICl0Wb","executionInfo":{"status":"ok","timestamp":1658831203994,"user_tz":-540,"elapsed":7,"user":{"displayName":"신현호","userId":"08804028255972704707"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def load_data():\n","    train = pd.read_csv('./data/train.csv')\n","    valid = pd.read_csv('./data/val.csv')\n","    test = pd.read_csv('./data/test.csv')\n","\n","    return train, valid, test\n","\n","train, valid, test = load_data()"],"metadata":{"id":"D3C8uJsemDoq","executionInfo":{"status":"ok","timestamp":1658831207550,"user_tz":-540,"elapsed":3560,"user":{"displayName":"신현호","userId":"08804028255972704707"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"id":"9FH-4RFFGzhg","executionInfo":{"status":"ok","timestamp":1658831207550,"user_tz":-540,"elapsed":9,"user":{"displayName":"신현호","userId":"08804028255972704707"}},"outputId":"34ca3aac-ae18-47b8-81fe-bac0a283edac"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["             ID        V1        V2        V3        V4        V5        V6  \\\n","0       AAAA0x1 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n","1       AAAA0x2  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n","2       AAAA0x5 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n","3       AAAA0x7  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708   \n","4       AAAA0xc  0.384978  0.616109 -0.874300 -0.094019  2.924584  3.317027   \n","...         ...       ...       ...       ...       ...       ...       ...   \n","142498  0x4587f  0.219529  0.881246 -0.635891  0.960928 -0.152971 -1.014307   \n","142499  0x45880 -1.775135 -0.004235  1.189786  0.331096  1.196063  5.519980   \n","142500  0x45884 -0.732789 -0.055080  2.035030 -0.738589  0.868229  1.058415   \n","142501  0x45885  1.919565 -0.301254 -3.249640 -0.557828  2.630515  3.031260   \n","142502  0x45887 -0.533413 -0.189733  0.703337 -0.506271 -0.012546 -0.649617   \n","\n","              V7        V8        V9  ...       V21       V22       V23  \\\n","0       0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474   \n","1      -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288   \n","2       0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458   \n","3      -0.005159  0.081213  0.464960  ... -0.167716 -0.270710 -0.154104   \n","4       0.470455  0.538247 -0.558895  ...  0.049924  0.238422  0.009130   \n","...          ...       ...       ...  ...       ...       ...       ...   \n","142498  0.427126  0.121340 -0.285670  ...  0.099936  0.337120  0.251791   \n","142499 -1.518185  2.080825  1.159498  ...  0.103302  0.654850 -0.348929   \n","142500  0.024330  0.294869  0.584800  ...  0.214205  0.924384  0.012463   \n","142501 -0.296827  0.708417  0.432454  ...  0.232045  0.578229 -0.037501   \n","142502  1.577006 -0.414650  0.486180  ...  0.261057  0.643078  0.376777   \n","\n","             V24       V25       V26       V27       V28       V29       V30  \n","0       0.066928  0.128539 -0.189115  0.133558 -0.021053  1.783274 -0.994983  \n","1      -0.339846  0.167170  0.125895 -0.008983  0.014724 -0.269825 -0.994983  \n","2       0.141267 -0.206010  0.502292  0.219422  0.215153  0.670579 -0.994960  \n","3      -0.780055  0.750137 -0.257237  0.034507  0.005168 -0.237686 -0.994937  \n","4       0.996710 -0.767315 -0.492208  0.042472 -0.054337 -0.167819 -0.994866  \n","...          ...       ...       ...       ...       ...       ...       ...  \n","142498  0.057688 -1.508368  0.144023  0.181205  0.215243  0.028645  1.034904  \n","142499  0.745323  0.704545 -0.127579  0.454379  0.130308  0.810312  1.034916  \n","142500 -1.016226 -0.606624 -0.395255  0.068472 -0.053527  0.038986  1.034963  \n","142501  0.640134  0.265745 -0.087371  0.004455 -0.026561  0.641096  1.034975  \n","142502  0.008797 -0.473649 -0.818267 -0.002415  0.013649  2.724796  1.035022  \n","\n","[142503 rows x 31 columns]"],"text/html":["\n","  <div id=\"df-71b1c90d-2796-4185-8ff3-ae963787c619\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>V1</th>\n","      <th>V2</th>\n","      <th>V3</th>\n","      <th>V4</th>\n","      <th>V5</th>\n","      <th>V6</th>\n","      <th>V7</th>\n","      <th>V8</th>\n","      <th>V9</th>\n","      <th>...</th>\n","      <th>V21</th>\n","      <th>V22</th>\n","      <th>V23</th>\n","      <th>V24</th>\n","      <th>V25</th>\n","      <th>V26</th>\n","      <th>V27</th>\n","      <th>V28</th>\n","      <th>V29</th>\n","      <th>V30</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AAAA0x1</td>\n","      <td>-1.359807</td>\n","      <td>-0.072781</td>\n","      <td>2.536347</td>\n","      <td>1.378155</td>\n","      <td>-0.338321</td>\n","      <td>0.462388</td>\n","      <td>0.239599</td>\n","      <td>0.098698</td>\n","      <td>0.363787</td>\n","      <td>...</td>\n","      <td>-0.018307</td>\n","      <td>0.277838</td>\n","      <td>-0.110474</td>\n","      <td>0.066928</td>\n","      <td>0.128539</td>\n","      <td>-0.189115</td>\n","      <td>0.133558</td>\n","      <td>-0.021053</td>\n","      <td>1.783274</td>\n","      <td>-0.994983</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>AAAA0x2</td>\n","      <td>1.191857</td>\n","      <td>0.266151</td>\n","      <td>0.166480</td>\n","      <td>0.448154</td>\n","      <td>0.060018</td>\n","      <td>-0.082361</td>\n","      <td>-0.078803</td>\n","      <td>0.085102</td>\n","      <td>-0.255425</td>\n","      <td>...</td>\n","      <td>-0.225775</td>\n","      <td>-0.638672</td>\n","      <td>0.101288</td>\n","      <td>-0.339846</td>\n","      <td>0.167170</td>\n","      <td>0.125895</td>\n","      <td>-0.008983</td>\n","      <td>0.014724</td>\n","      <td>-0.269825</td>\n","      <td>-0.994983</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>AAAA0x5</td>\n","      <td>-1.158233</td>\n","      <td>0.877737</td>\n","      <td>1.548718</td>\n","      <td>0.403034</td>\n","      <td>-0.407193</td>\n","      <td>0.095921</td>\n","      <td>0.592941</td>\n","      <td>-0.270533</td>\n","      <td>0.817739</td>\n","      <td>...</td>\n","      <td>-0.009431</td>\n","      <td>0.798278</td>\n","      <td>-0.137458</td>\n","      <td>0.141267</td>\n","      <td>-0.206010</td>\n","      <td>0.502292</td>\n","      <td>0.219422</td>\n","      <td>0.215153</td>\n","      <td>0.670579</td>\n","      <td>-0.994960</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>AAAA0x7</td>\n","      <td>1.229658</td>\n","      <td>0.141004</td>\n","      <td>0.045371</td>\n","      <td>1.202613</td>\n","      <td>0.191881</td>\n","      <td>0.272708</td>\n","      <td>-0.005159</td>\n","      <td>0.081213</td>\n","      <td>0.464960</td>\n","      <td>...</td>\n","      <td>-0.167716</td>\n","      <td>-0.270710</td>\n","      <td>-0.154104</td>\n","      <td>-0.780055</td>\n","      <td>0.750137</td>\n","      <td>-0.257237</td>\n","      <td>0.034507</td>\n","      <td>0.005168</td>\n","      <td>-0.237686</td>\n","      <td>-0.994937</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>AAAA0xc</td>\n","      <td>0.384978</td>\n","      <td>0.616109</td>\n","      <td>-0.874300</td>\n","      <td>-0.094019</td>\n","      <td>2.924584</td>\n","      <td>3.317027</td>\n","      <td>0.470455</td>\n","      <td>0.538247</td>\n","      <td>-0.558895</td>\n","      <td>...</td>\n","      <td>0.049924</td>\n","      <td>0.238422</td>\n","      <td>0.009130</td>\n","      <td>0.996710</td>\n","      <td>-0.767315</td>\n","      <td>-0.492208</td>\n","      <td>0.042472</td>\n","      <td>-0.054337</td>\n","      <td>-0.167819</td>\n","      <td>-0.994866</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>142498</th>\n","      <td>0x4587f</td>\n","      <td>0.219529</td>\n","      <td>0.881246</td>\n","      <td>-0.635891</td>\n","      <td>0.960928</td>\n","      <td>-0.152971</td>\n","      <td>-1.014307</td>\n","      <td>0.427126</td>\n","      <td>0.121340</td>\n","      <td>-0.285670</td>\n","      <td>...</td>\n","      <td>0.099936</td>\n","      <td>0.337120</td>\n","      <td>0.251791</td>\n","      <td>0.057688</td>\n","      <td>-1.508368</td>\n","      <td>0.144023</td>\n","      <td>0.181205</td>\n","      <td>0.215243</td>\n","      <td>0.028645</td>\n","      <td>1.034904</td>\n","    </tr>\n","    <tr>\n","      <th>142499</th>\n","      <td>0x45880</td>\n","      <td>-1.775135</td>\n","      <td>-0.004235</td>\n","      <td>1.189786</td>\n","      <td>0.331096</td>\n","      <td>1.196063</td>\n","      <td>5.519980</td>\n","      <td>-1.518185</td>\n","      <td>2.080825</td>\n","      <td>1.159498</td>\n","      <td>...</td>\n","      <td>0.103302</td>\n","      <td>0.654850</td>\n","      <td>-0.348929</td>\n","      <td>0.745323</td>\n","      <td>0.704545</td>\n","      <td>-0.127579</td>\n","      <td>0.454379</td>\n","      <td>0.130308</td>\n","      <td>0.810312</td>\n","      <td>1.034916</td>\n","    </tr>\n","    <tr>\n","      <th>142500</th>\n","      <td>0x45884</td>\n","      <td>-0.732789</td>\n","      <td>-0.055080</td>\n","      <td>2.035030</td>\n","      <td>-0.738589</td>\n","      <td>0.868229</td>\n","      <td>1.058415</td>\n","      <td>0.024330</td>\n","      <td>0.294869</td>\n","      <td>0.584800</td>\n","      <td>...</td>\n","      <td>0.214205</td>\n","      <td>0.924384</td>\n","      <td>0.012463</td>\n","      <td>-1.016226</td>\n","      <td>-0.606624</td>\n","      <td>-0.395255</td>\n","      <td>0.068472</td>\n","      <td>-0.053527</td>\n","      <td>0.038986</td>\n","      <td>1.034963</td>\n","    </tr>\n","    <tr>\n","      <th>142501</th>\n","      <td>0x45885</td>\n","      <td>1.919565</td>\n","      <td>-0.301254</td>\n","      <td>-3.249640</td>\n","      <td>-0.557828</td>\n","      <td>2.630515</td>\n","      <td>3.031260</td>\n","      <td>-0.296827</td>\n","      <td>0.708417</td>\n","      <td>0.432454</td>\n","      <td>...</td>\n","      <td>0.232045</td>\n","      <td>0.578229</td>\n","      <td>-0.037501</td>\n","      <td>0.640134</td>\n","      <td>0.265745</td>\n","      <td>-0.087371</td>\n","      <td>0.004455</td>\n","      <td>-0.026561</td>\n","      <td>0.641096</td>\n","      <td>1.034975</td>\n","    </tr>\n","    <tr>\n","      <th>142502</th>\n","      <td>0x45887</td>\n","      <td>-0.533413</td>\n","      <td>-0.189733</td>\n","      <td>0.703337</td>\n","      <td>-0.506271</td>\n","      <td>-0.012546</td>\n","      <td>-0.649617</td>\n","      <td>1.577006</td>\n","      <td>-0.414650</td>\n","      <td>0.486180</td>\n","      <td>...</td>\n","      <td>0.261057</td>\n","      <td>0.643078</td>\n","      <td>0.376777</td>\n","      <td>0.008797</td>\n","      <td>-0.473649</td>\n","      <td>-0.818267</td>\n","      <td>-0.002415</td>\n","      <td>0.013649</td>\n","      <td>2.724796</td>\n","      <td>1.035022</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>142503 rows × 31 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71b1c90d-2796-4185-8ff3-ae963787c619')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-71b1c90d-2796-4185-8ff3-ae963787c619 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-71b1c90d-2796-4185-8ff3-ae963787c619');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["def preprocess(train, valid, test):\n","    train.drop(['ID'], inplace = True, axis = 1)\n","    valid.drop(['ID'], inplace = True, axis = 1)\n","    test.drop(['ID'], inplace = True, axis = 1)\n","\n","    X_train = train.values\n","    X_valid = valid.drop(['Class'], axis = 1).values\n","    y_valid = valid['Class'].values\n","    X_test = test.values\n","\n","    return X_train, X_valid, y_valid, X_test\n","\n","X_train, X_valid, y_valid, X_test = preprocess(train, valid, test)"],"metadata":{"id":"MjCWaAsqGoZA","executionInfo":{"status":"ok","timestamp":1658831207551,"user_tz":-540,"elapsed":7,"user":{"displayName":"신현호","userId":"08804028255972704707"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# AutoEncoder with sub-sampling\n","- 학습과정에서 모델의 크기가 커지거나 epoch수가 늘어나면 f1 score가 감소함\n","    - 모델이 이상치까지 학습하는 것으로 볼 수 있음\n","\n","- Isolation Forest 논문에서 제시한 sub-sampling 기법을 autoencoder에 적용\n","    - sub-sampling을 통해서 이상치 탐지에 있어 `masking problem`과 `swamping preblem`을 완화할 수 있다."],"metadata":{"id":"0wqFDJZGC0_l"}},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import argparse\n","from tqdm import tqdm\n","import random\n","from itertools import product\n","from sklearn.metrics import f1_score, confusion_matrix"],"metadata":{"id":"XPszMM2t0j_Q","executionInfo":{"status":"ok","timestamp":1658831324832,"user_tz":-540,"elapsed":2952,"user":{"displayName":"신현호","userId":"08804028255972704707"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def set_seed(seed: int = 42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed) \n","    torch.backends.cudnn.deterministic = True \n","    torch.backends.cudnn.benchmark = True\n","\n","set_seed(123)"],"metadata":{"id":"fqc_LZrN4oin","executionInfo":{"status":"ok","timestamp":1658831325496,"user_tz":-540,"elapsed":2,"user":{"displayName":"신현호","userId":"08804028255972704707"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["class AutoEncoder(nn.Module):\n","\n","    def __init__(self, input_size, encoder_hidden_size, bottle_neck_size, decoder_hidden_size, dropout_p):\n","        self.input_size = input_size\n","        self.encoder_hidden_size = encoder_hidden_size\n","        self.bottle_neck_size = bottle_neck_size\n","        self.decoder_hidden_size = decoder_hidden_size\n","        self.dropout_p = dropout_p\n","\n","        super(AutoEncoder, self).__init__()\n","\n","\n","        # ===== Encoder ===== #\n","        self.encoder = nn.ModuleList()\n","        # input layer\n","        self.encoder.append(nn.Sequential(\n","            nn.Linear(input_size, encoder_hidden_size[0]),\n","            nn.BatchNorm1d(encoder_hidden_size[0]),\n","            nn.ReLU(),\n","            nn.Dropout(dropout_p)\n","        ))\n","        # encoder hidden layers\n","        for idx in range(len(encoder_hidden_size) - 1):\n","            self.encoder.append(nn.Sequential(\n","                nn.Linear(encoder_hidden_size[idx], encoder_hidden_size[idx + 1]),\n","                nn.BatchNorm1d(encoder_hidden_size[idx + 1]),\n","                nn.ReLU(),\n","                nn.Dropout(dropout_p)\n","            ))\n","        # bottle neck layer\n","        self.encoder.append(nn.Sequential(\n","            nn.Linear(encoder_hidden_size[-1], bottle_neck_size),\n","            nn.BatchNorm1d(bottle_neck_size),\n","            nn.ReLU(),\n","            nn.Dropout(dropout_p)\n","        ))\n","\n","\n","        # ===== Decoder ===== #\n","        self.decoder = nn.ModuleList()\n","        # bottle neck\n","        self.decoder.append(nn.Sequential(\n","            nn.Linear(bottle_neck_size, decoder_hidden_size[0]),\n","            nn.BatchNorm1d(decoder_hidden_size[0]),\n","            nn.ReLU(),\n","            nn.Dropout(dropout_p)\n","        ))\n","        # decoder hidden layers\n","        for idx in range(len(decoder_hidden_size) - 1):\n","            self.decoder.append(nn.Sequential(\n","                nn.Linear(decoder_hidden_size[idx], decoder_hidden_size[idx + 1]),\n","                nn.BatchNorm1d(decoder_hidden_size[idx + 1]),\n","                nn.ReLU(),\n","                nn.Dropout(dropout_p)\n","            ))\n","        # output_layer\n","        self.decoder.append(nn.Linear(decoder_hidden_size[-1], input_size))\n","\n","\n","    def forward(self, x):\n","        # |x| = (batch_size, input_size)\n","        for layer in self.encoder:\n","            x = layer(x)\n","        \n","        latent = x\n","        # |latent| = (batch_size, bottle_neck_size)\n","\n","        for layer in self.decoder:\n","            x = layer(x)\n","        # |x| = (batch_size, input_size)\n","\n","        return x\n","\n","\n","class AutoEncoderWithSubSampling(nn.Module):\n","\n","    def __init__(self, n_estimators, input_size, encoder_hidden_size, bottle_neck_size, decoder_hidden_size, dropout_p):\n","        self.n_estimators = n_estimators\n","        self.input_size = input_size\n","        self.encoder_hidden_size = encoder_hidden_size\n","        self.bottle_neck_size = bottle_neck_size\n","        self.decoder_hidden_size = decoder_hidden_size\n","        self.dropout_p = dropout_p\n","\n","        super(AutoEncoderWithSubSampling, self).__init__()\n","\n","        self.estimators = [\n","            AutoEncoder(\n","                input_size = input_size,\n","                encoder_hidden_size = encoder_hidden_size,\n","                bottle_neck_size = bottle_neck_size,\n","                decoder_hidden_size = decoder_hidden_size,\n","                dropout_p = dropout_p\n","            ) for _ in range(n_estimators)\n","        ]\n","    \n","    def forward(self):\n","        pass\n","\n","    def train(self, train_loaders, valid_loader, y_valid, n_epochs, device):\n","        for idx in range(len(train_loaders)):\n","            display(Markdown('# Estimator {}/{}'.format((idx + 1), len(train_loaders))))\n","\n","            sub_model = self.estimators[idx]\n","            sub_model.to(device)\n","            sub_loader = train_loaders[idx]\n","\n","            optimizer = optim.Adam(sub_model.parameters())\n","            crit = nn.L1Loss()\n","            cos = nn.CosineSimilarity(dim = 1)\n","\n","\n","            best_f1 = -np.inf\n","            best_model = None\n","            for epoch in range(n_epochs):\n","                train_losses = []\n","                valid_losses = []\n","                preds = []\n","                # === train === #\n","                for batch in sub_loader:\n","                    batch = batch.float().to(device)\n","\n","                    # initialize optimizer\n","                    optimizer.zero_grad()\n","\n","                    # feed foward\n","                    x_hat = sub_model(batch)\n","\n","                    # loss\n","                    loss = crit(batch, x_hat)\n","\n","                    # backpropagation\n","                    loss.backward()\n","\n","                    # gradient descent\n","                    optimizer.step()\n","\n","                    train_losses.append(float(loss))\n","\n","                # === valid === #                \n","                for batch in valid_loader:\n","                    batch = batch.float().to(device)\n","\n","                    sub_model.eval()\n","                    with torch.no_grad():\n","                        # feed foward\n","                        x_hat = sub_model(batch)\n","\n","                        # loss\n","                        loss = crit(batch, x_hat) \n","                        valid_losses.append(float(loss))\n","\n","                        # cosine similarity\n","                        sim = cos(batch, x_hat).detach().cpu().numpy()\n","\n","                        pred = (sim < 0.95)\n","                        preds.extend(pred)\n","\n","                train_loss = np.mean(train_losses)\n","                valid_loss = np.mean(valid_losses)\n","                f1 = f1_score(y_valid, preds, average = 'macro')\n","\n","                if f1 > best_f1:\n","                    best_model = sub_model.state_dict()\n","                    best_f1 = f1\n","\n","                if epoch % 20 == 0:\n","                    print(f'Epoch {epoch + 1} - Loss {np.round(train_loss, 5)}, Val_Loss {np.round(valid_loss, 5)}, f1_score {np.round(f1, 5)}')\n","\n","    def evaluate(self, X, batch_size, device):\n","        ensemble = []\n","\n","        cos = nn.CosineSimilarity(dim = 1)\n","        \n","        for estimator in self.estimators:\n","            estimator.to(device)\n","\n","            sims = []\n","\n","            estimator.eval()\n","            with torch.no_grad():\n","                for idx in range(0, len(X), batch_size):\n","                    batch = X[idx: idx + batch_size]\n","                    batch = torch.FloatTensor(batch).to(device)\n","\n","                    x_hat = estimator(batch)\n","\n","                    sim = cos(batch, x_hat).detach().cpu().numpy()\n","\n","                    sims.extend(sim)\n","            \n","            ensemble.append(sims)\n","        \n","        ave_sims = np.mean(ensemble, axis = 0)\n","\n","        pred = (ave_sims < 0.95)\n","\n","        return pred"],"metadata":{"id":"YPIU7chRL9OS","executionInfo":{"status":"ok","timestamp":1658837924676,"user_tz":-540,"elapsed":743,"user":{"displayName":"신현호","userId":"08804028255972704707"}}},"execution_count":66,"outputs":[]},{"cell_type":"code","source":["class AE_Dataset(Dataset):\n","\n","    def __init__(self, x):\n","        self.x = x\n","    \n","    def __len__(self):\n","        return len(self.x)\n","    \n","    def __getitem__(self, idx):\n","        return self.x[idx]\n","\n","\n","def get_loader(train, valid, batch_size, shuffle = True):\n","    train_loader = DataLoader(\n","        AE_Dataset(train),\n","        batch_size = batch_size,\n","        shuffle = shuffle\n","    )\n","    valid_loader = DataLoader(\n","        AE_Dataset(valid),\n","        batch_size = batch_size,\n","        shuffle = False\n","    )    \n","\n","    return train_loader, valid_loader\n","\n","def sub_sampler(train, valid, batch_size, sampling_size, shuffle  = True):\n","    train_loaders = []\n","\n","    # ===== sub-sampling ===== #\n","    # shuffle data\n","    if shuffle:\n","        indices = np.random.permutation(len(train))\n","        train = train[indices]\n","    \n","    # split data\n","    for idx in range(0, len(train), sampling_size):\n","        sampled_data = train[idx : idx + sampling_size]\n","\n","        sampled_loader = DataLoader(\n","            AE_Dataset(sampled_data),\n","            batch_size = batch_size,\n","            shuffle = shuffle\n","        )\n","        train_loaders.append(sampled_loader)\n","\n","    # ===== valid loader ===== #\n","    valid_loader = DataLoader(\n","        AE_Dataset(valid),\n","        batch_size = batch_size,\n","        shuffle = False\n","    )\n","\n","    return train_loaders, valid_loader"],"metadata":{"id":"_eW6ijd_R3z-","executionInfo":{"status":"ok","timestamp":1658837926561,"user_tz":-540,"elapsed":425,"user":{"displayName":"신현호","userId":"08804028255972704707"}}},"execution_count":67,"outputs":[]},{"cell_type":"code","source":["DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","train_loaders, valid_loader = sub_sampler(\n","    X_train, X_valid,\n","    batch_size = 512,\n","    sampling_size = 8192,\n","    shuffle = True\n",")\n","\n","model = AutoEncoderWithSubSampling(\n","    n_estimators = len(train_loaders),\n","    input_size = 30,\n","    encoder_hidden_size = [60],\n","    bottle_neck_size = 120,\n","    decoder_hidden_size = [60],\n","    dropout_p = .2\n",")\n","\n","model.train(\n","    train_loaders,\n","    valid_loader,\n","    y_valid,\n","    n_epochs = 200,\n","    device = DEVICE\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"eEgyf-34P6m6","executionInfo":{"status":"ok","timestamp":1658838744231,"user_tz":-540,"elapsed":747476,"user":{"displayName":"신현호","userId":"08804028255972704707"}},"outputId":"6d18f1cf-f240-4d88-bf85-c6fc3f370303"},"execution_count":72,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"# Estimator 1/14"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 - Loss 0.69355, Val_Loss 0.63106, f1_score 0.00105\n","Epoch 21 - Loss 0.08638, Val_Loss 0.08794, f1_score 0.52064\n","Epoch 41 - Loss 0.05217, Val_Loss 0.05498, f1_score 0.80837\n","Epoch 61 - Loss 0.04467, Val_Loss 0.04637, f1_score 0.89671\n","Epoch 81 - Loss 0.03646, Val_Loss 0.03855, f1_score 0.90974\n","Epoch 101 - Loss 0.03799, Val_Loss 0.04006, f1_score 0.91658\n","Epoch 121 - Loss 0.03713, Val_Loss 0.03504, f1_score 0.91658\n","Epoch 141 - Loss 0.03308, Val_Loss 0.03202, f1_score 0.91658\n","Epoch 161 - Loss 0.0376, Val_Loss 0.04068, f1_score 0.91658\n","Epoch 181 - Loss 0.03571, Val_Loss 0.04109, f1_score 0.91658\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"# Estimator 2/14"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 - Loss 0.6851, Val_Loss 0.62352, f1_score 0.00105\n","Epoch 21 - Loss 0.0865, Val_Loss 0.08306, f1_score 0.53609\n","Epoch 41 - Loss 0.05322, Val_Loss 0.05595, f1_score 0.63035\n","Epoch 61 - Loss 0.04345, Val_Loss 0.03763, f1_score 0.83763\n","Epoch 81 - Loss 0.03491, Val_Loss 0.03474, f1_score 0.88448\n","Epoch 101 - Loss 0.03339, Val_Loss 0.03819, f1_score 0.88697\n","Epoch 121 - Loss 0.0367, Val_Loss 0.04398, f1_score 0.69025\n","Epoch 141 - Loss 0.03349, Val_Loss 0.03298, f1_score 0.53003\n","Epoch 161 - Loss 0.03351, Val_Loss 0.03347, f1_score 0.53003\n","Epoch 181 - Loss 0.0348, Val_Loss 0.03679, f1_score 0.53099\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"# Estimator 3/14"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 - Loss 0.6767, Val_Loss 0.62573, f1_score 0.00105\n","Epoch 21 - Loss 0.08679, Val_Loss 0.08959, f1_score 0.54537\n","Epoch 41 - Loss 0.04803, Val_Loss 0.0533, f1_score 0.77436\n","Epoch 61 - Loss 0.04403, Val_Loss 0.04769, f1_score 0.81321\n","Epoch 81 - Loss 0.03942, Val_Loss 0.04271, f1_score 0.4997\n","Epoch 101 - Loss 0.0348, Val_Loss 0.03999, f1_score 0.4997\n","Epoch 121 - Loss 0.03174, Val_Loss 0.0379, f1_score 0.49971\n","Epoch 141 - Loss 0.02945, Val_Loss 0.03137, f1_score 0.49972\n","Epoch 161 - Loss 0.03079, Val_Loss 0.03151, f1_score 0.49972\n","Epoch 181 - Loss 0.03161, Val_Loss 0.03227, f1_score 0.49973\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"# Estimator 4/14"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 - Loss 0.68988, Val_Loss 0.62753, f1_score 0.00105\n","Epoch 21 - Loss 0.07839, Val_Loss 0.08213, f1_score 0.646\n","Epoch 41 - Loss 0.05065, Val_Loss 0.05525, f1_score 0.77137\n","Epoch 61 - Loss 0.03876, Val_Loss 0.03628, f1_score 0.86749\n","Epoch 81 - Loss 0.03954, Val_Loss 0.04558, f1_score 0.8905\n","Epoch 101 - Loss 0.0389, Val_Loss 0.04049, f1_score 0.89671\n","Epoch 121 - Loss 0.03278, Val_Loss 0.03993, f1_score 0.90312\n","Epoch 141 - Loss 0.03038, Val_Loss 0.03402, f1_score 0.90312\n","Epoch 161 - Loss 0.0332, Val_Loss 0.03522, f1_score 0.90974\n","Epoch 181 - Loss 0.03214, Val_Loss 0.03964, f1_score 0.90974\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"# Estimator 5/14"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 - Loss 0.69236, Val_Loss 0.6253, f1_score 0.00105\n","Epoch 21 - Loss 0.08282, Val_Loss 0.085, f1_score 0.54634\n","Epoch 41 - Loss 0.05317, Val_Loss 0.05638, f1_score 0.8046\n","Epoch 61 - Loss 0.04602, Val_Loss 0.04908, f1_score 0.8905\n","Epoch 81 - Loss 0.04086, Val_Loss 0.03609, f1_score 0.90312\n","Epoch 101 - Loss 0.04036, Val_Loss 0.03586, f1_score 0.90312\n","Epoch 121 - Loss 0.03205, Val_Loss 0.03844, f1_score 0.90312\n","Epoch 141 - Loss 0.03824, Val_Loss 0.03684, f1_score 0.90312\n","Epoch 161 - Loss 0.03386, Val_Loss 0.03945, f1_score 0.90312\n","Epoch 181 - Loss 0.03317, Val_Loss 0.03189, f1_score 0.90974\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"# Estimator 6/14"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 - Loss 0.69301, Val_Loss 0.62743, f1_score 0.00105\n","Epoch 21 - Loss 0.08444, Val_Loss 0.08113, f1_score 0.51964\n","Epoch 41 - Loss 0.05231, Val_Loss 0.05885, f1_score 0.80091\n","Epoch 61 - Loss 0.04739, Val_Loss 0.05166, f1_score 0.87865\n","Epoch 81 - Loss 0.04296, Val_Loss 0.04833, f1_score 0.90312\n","Epoch 101 - Loss 0.03561, Val_Loss 0.0373, f1_score 0.91658\n","Epoch 121 - Loss 0.0339, Val_Loss 0.03613, f1_score 0.91658\n","Epoch 141 - Loss 0.03386, Val_Loss 0.03775, f1_score 0.91658\n","Epoch 161 - Loss 0.03331, Val_Loss 0.03721, f1_score 0.6949\n","Epoch 181 - Loss 0.02987, Val_Loss 0.03289, f1_score 0.69979\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"# Estimator 7/14"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 - Loss 0.69508, Val_Loss 0.62957, f1_score 0.00105\n","Epoch 21 - Loss 0.07713, Val_Loss 0.08256, f1_score 0.59783\n","Epoch 41 - Loss 0.05576, Val_Loss 0.0599, f1_score 0.76557\n","Epoch 61 - Loss 0.04388, Val_Loss 0.0458, f1_score 0.84703\n","Epoch 81 - Loss 0.04198, Val_Loss 0.04911, f1_score 0.89671\n","Epoch 101 - Loss 0.03397, Val_Loss 0.03762, f1_score 0.91658\n","Epoch 121 - Loss 0.0298, Val_Loss 0.03114, f1_score 0.91658\n","Epoch 141 - Loss 0.03548, Val_Loss 0.03206, f1_score 0.91658\n","Epoch 161 - Loss 0.03583, Val_Loss 0.03768, f1_score 0.91658\n","Epoch 181 - Loss 0.03079, Val_Loss 0.03382, f1_score 0.91658\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"# Estimator 8/14"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 - Loss 0.68554, Val_Loss 0.62934, f1_score 0.00105\n","Epoch 21 - Loss 0.08328, Val_Loss 0.08186, f1_score 0.53734\n","Epoch 41 - Loss 0.05168, Val_Loss 0.05356, f1_score 0.80837\n","Epoch 61 - Loss 0.04463, Val_Loss 0.04663, f1_score 0.86749\n","Epoch 81 - Loss 0.04679, Val_Loss 0.04501, f1_score 0.87298\n","Epoch 101 - Loss 0.03468, Val_Loss 0.03834, f1_score 0.8905\n","Epoch 121 - Loss 0.03523, Val_Loss 0.03508, f1_score 0.8905\n","Epoch 141 - Loss 0.03462, Val_Loss 0.03381, f1_score 0.85578\n","Epoch 161 - Loss 0.03231, Val_Loss 0.02886, f1_score 0.49971\n","Epoch 181 - Loss 0.03339, Val_Loss 0.02954, f1_score 0.49971\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"# Estimator 9/14"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 - Loss 0.68837, Val_Loss 0.63104, f1_score 0.00105\n","Epoch 21 - Loss 0.07939, Val_Loss 0.0785, f1_score 0.54391\n","Epoch 41 - Loss 0.05288, Val_Loss 0.05746, f1_score 0.79381\n","Epoch 61 - Loss 0.04358, Val_Loss 0.04376, f1_score 0.8905\n","Epoch 81 - Loss 0.04282, Val_Loss 0.0383, f1_score 0.90974\n","Epoch 101 - Loss 0.03819, Val_Loss 0.04503, f1_score 0.90974\n","Epoch 121 - Loss 0.0324, Val_Loss 0.03739, f1_score 0.90974\n","Epoch 141 - Loss 0.03167, Val_Loss 0.0289, f1_score 0.90974\n","Epoch 161 - Loss 0.03945, Val_Loss 0.0337, f1_score 0.91658\n","Epoch 181 - Loss 0.03178, Val_Loss 0.02879, f1_score 0.91658\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"# Estimator 10/14"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 - Loss 0.68011, Val_Loss 0.62552, f1_score 0.00105\n","Epoch 21 - Loss 0.08369, Val_Loss 0.08626, f1_score 0.54176\n","Epoch 41 - Loss 0.05471, Val_Loss 0.05199, f1_score 0.73991\n","Epoch 61 - Loss 0.04834, Val_Loss 0.05372, f1_score 0.81224\n","Epoch 81 - Loss 0.04195, Val_Loss 0.04767, f1_score 0.87865\n","Epoch 101 - Loss 0.03853, Val_Loss 0.04026, f1_score 0.89671\n","Epoch 121 - Loss 0.03484, Val_Loss 0.03425, f1_score 0.90312\n","Epoch 141 - Loss 0.03166, Val_Loss 0.03459, f1_score 0.90312\n","Epoch 161 - Loss 0.03067, Val_Loss 0.03693, f1_score 0.90312\n","Epoch 181 - Loss 0.02898, Val_Loss 0.03154, f1_score 0.90312\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"# Estimator 11/14"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 - Loss 0.68179, Val_Loss 0.62234, f1_score 0.00105\n","Epoch 21 - Loss 0.08378, Val_Loss 0.08266, f1_score 0.55891\n","Epoch 41 - Loss 0.04616, Val_Loss 0.04542, f1_score 0.77743\n","Epoch 61 - Loss 0.04164, Val_Loss 0.038, f1_score 0.83311\n","Epoch 81 - Loss 0.03912, Val_Loss 0.03684, f1_score 0.86348\n","Epoch 101 - Loss 0.0359, Val_Loss 0.04351, f1_score 0.76902\n","Epoch 121 - Loss 0.03395, Val_Loss 0.0261, f1_score 0.49972\n","Epoch 141 - Loss 0.03325, Val_Loss 0.03348, f1_score 0.49973\n","Epoch 161 - Loss 0.03181, Val_Loss 0.02661, f1_score 0.49973\n","Epoch 181 - Loss 0.03095, Val_Loss 0.03007, f1_score 0.49973\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"# Estimator 12/14"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 - Loss 0.683, Val_Loss 0.62544, f1_score 0.00105\n","Epoch 21 - Loss 0.08872, Val_Loss 0.08586, f1_score 0.52185\n","Epoch 41 - Loss 0.05411, Val_Loss 0.05636, f1_score 0.79381\n","Epoch 61 - Loss 0.04866, Val_Loss 0.04171, f1_score 0.87083\n","Epoch 81 - Loss 0.04823, Val_Loss 0.05116, f1_score 0.86829\n","Epoch 101 - Loss 0.0365, Val_Loss 0.03258, f1_score 0.69025\n","Epoch 121 - Loss 0.04227, Val_Loss 0.04919, f1_score 0.49974\n","Epoch 141 - Loss 0.03865, Val_Loss 0.03538, f1_score 0.49974\n","Epoch 161 - Loss 0.0342, Val_Loss 0.03922, f1_score 0.49974\n","Epoch 181 - Loss 0.03288, Val_Loss 0.03369, f1_score 0.49974\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"# Estimator 13/14"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 - Loss 0.69262, Val_Loss 0.63386, f1_score 0.00105\n","Epoch 21 - Loss 0.08491, Val_Loss 0.08875, f1_score 0.52732\n","Epoch 41 - Loss 0.056, Val_Loss 0.05514, f1_score 0.55507\n","Epoch 61 - Loss 0.04626, Val_Loss 0.04991, f1_score 0.56571\n","Epoch 81 - Loss 0.03957, Val_Loss 0.039, f1_score 0.72068\n","Epoch 101 - Loss 0.04155, Val_Loss 0.04087, f1_score 0.90974\n","Epoch 121 - Loss 0.03417, Val_Loss 0.03591, f1_score 0.90974\n","Epoch 141 - Loss 0.03098, Val_Loss 0.03075, f1_score 0.91658\n","Epoch 161 - Loss 0.03379, Val_Loss 0.03656, f1_score 0.90974\n","Epoch 181 - Loss 0.03476, Val_Loss 0.0313, f1_score 0.91658\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"# Estimator 14/14"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 - Loss 0.68826, Val_Loss 0.63477, f1_score 0.00105\n","Epoch 21 - Loss 0.091, Val_Loss 0.09392, f1_score 0.52189\n","Epoch 41 - Loss 0.05758, Val_Loss 0.05636, f1_score 0.60475\n","Epoch 61 - Loss 0.0419, Val_Loss 0.04449, f1_score 0.89671\n","Epoch 81 - Loss 0.04453, Val_Loss 0.04238, f1_score 0.90974\n","Epoch 101 - Loss 0.0383, Val_Loss 0.03828, f1_score 0.90974\n","Epoch 121 - Loss 0.03367, Val_Loss 0.03548, f1_score 0.91658\n","Epoch 141 - Loss 0.03459, Val_Loss 0.03479, f1_score 0.91658\n","Epoch 161 - Loss 0.03378, Val_Loss 0.03393, f1_score 0.91658\n","Epoch 181 - Loss 0.03306, Val_Loss 0.03145, f1_score 0.91658\n"]}]},{"cell_type":"code","source":["val_pred = model.evaluate(\n","    X_valid,\n","    batch_size = 512,\n","    device = DEVICE\n",")"],"metadata":{"id":"HSeNrESIYDkE","executionInfo":{"status":"ok","timestamp":1658839410959,"user_tz":-540,"elapsed":1157,"user":{"displayName":"신현호","userId":"08804028255972704707"}}},"execution_count":73,"outputs":[]},{"cell_type":"code","source":["f1_score(y_valid, val_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nYArtx8fcU5G","executionInfo":{"status":"ok","timestamp":1658839415262,"user_tz":-540,"elapsed":251,"user":{"displayName":"신현호","userId":"08804028255972704707"}},"outputId":"b2bbe4d9-c5d5-42a7-87bd-4140ad96a92d"},"execution_count":74,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8333333333333334"]},"metadata":{},"execution_count":74}]},{"cell_type":"code","source":["pred = model.evaluate(\n","    X_test,\n","    batch_size = 512,\n","    device = DEVICE\n",")"],"metadata":{"id":"AvVqQz01crpG","executionInfo":{"status":"ok","timestamp":1658839515382,"user_tz":-540,"elapsed":4055,"user":{"displayName":"신현호","userId":"08804028255972704707"}}},"execution_count":75,"outputs":[]},{"cell_type":"code","source":["submission = pd.read_csv('./data/sample_submission.csv')"],"metadata":{"id":"0Z2kspMSii6i","executionInfo":{"status":"ok","timestamp":1658839537712,"user_tz":-540,"elapsed":523,"user":{"displayName":"신현호","userId":"08804028255972704707"}}},"execution_count":77,"outputs":[]},{"cell_type":"code","source":["submission['Class'] = pred.astype('int')"],"metadata":{"id":"RckfJ85OikRO","executionInfo":{"status":"ok","timestamp":1658839627089,"user_tz":-540,"elapsed":276,"user":{"displayName":"신현호","userId":"08804028255972704707"}}},"execution_count":81,"outputs":[]},{"cell_type":"code","source":["submission"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"C-FV-Mfji_4A","executionInfo":{"status":"ok","timestamp":1658839633851,"user_tz":-540,"elapsed":299,"user":{"displayName":"신현호","userId":"08804028255972704707"}},"outputId":"fc5aec52-24f6-406c-faae-566773319a6d"},"execution_count":82,"outputs":[{"output_type":"execute_result","data":{"text/plain":["             ID  Class\n","0       AAAA0x1      0\n","1       AAAA0x2      0\n","2       AAAA0x5      0\n","3       AAAA0x7      0\n","4       AAAA0xc      0\n","...         ...    ...\n","142498  0x4587f      0\n","142499  0x45880      0\n","142500  0x45884      0\n","142501  0x45885      0\n","142502  0x45887      0\n","\n","[142503 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-2bd41eb9-bcce-46ee-b375-707c7591c731\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AAAA0x1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>AAAA0x2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>AAAA0x5</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>AAAA0x7</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>AAAA0xc</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>142498</th>\n","      <td>0x4587f</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>142499</th>\n","      <td>0x45880</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>142500</th>\n","      <td>0x45884</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>142501</th>\n","      <td>0x45885</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>142502</th>\n","      <td>0x45887</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>142503 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2bd41eb9-bcce-46ee-b375-707c7591c731')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2bd41eb9-bcce-46ee-b375-707c7591c731 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2bd41eb9-bcce-46ee-b375-707c7591c731');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":82}]},{"cell_type":"code","source":["submission.to_csv('./AE_SubSampling.csv', index = False)"],"metadata":{"id":"tqyd7w2Siq59","executionInfo":{"status":"ok","timestamp":1658839637697,"user_tz":-540,"elapsed":2,"user":{"displayName":"신현호","userId":"08804028255972704707"}}},"execution_count":83,"outputs":[]}]}